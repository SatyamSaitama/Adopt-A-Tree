{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "27506ee1-1743-4c39-97b8-05b77449fe7e",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "27506ee1-1743-4c39-97b8-05b77449fe7e"
      },
      "source": [
        "In this experiment, we will train the GPT-2 model using the BookCorpus dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba355ae2-1291-41e8-b0cb-2aad000a6894",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "ba355ae2-1291-41e8-b0cb-2aad000a6894"
      },
      "source": [
        "Let's get started."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2db6e44-7caa-4c5d-9bf9-33ffa8e2da32",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "c2db6e44-7caa-4c5d-9bf9-33ffa8e2da32"
      },
      "source": [
        "<h1 style=\"color:Tomato;\"> Import the necessary Packages </h1>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "U0wgW6glR7qK",
        "outputId": "2f905ef0-1c5a-4100-fb4d-6d0565b1e832",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "U0wgW6glR7qK",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.3.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.3.0-py3-none-any.whl (484 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m484.9/484.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-3.3.0 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a3bd6282-647c-430f-ac56-2a0137b0f63f",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "a3bd6282-647c-430f-ac56-2a0137b0f63f",
        "outputId": "f66f0fa1-44bd-4195-c34b-4dee29b41df0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'datasets'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-86abb99e698e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# used in the previous experiments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mload_from_disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# used in the previous experiments\n",
        "from datasets import load_dataset,load_from_disk\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# for training\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "from transformers import GPT2Config, GPT2LMHeadModel\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "#for experiment tracking\n",
        "import wandb\n",
        "\n",
        "#common packages\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "import json\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2178fd67-5fe9-4364-9820-56e139d39622",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "2178fd67-5fe9-4364-9820-56e139d39622"
      },
      "source": [
        "<h1 style=\"color:Tomato;\"> Dataset </h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf30633e-d25f-4259-9f04-aea2d0101491",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "cf30633e-d25f-4259-9f04-aea2d0101491",
        "outputId": "39e4c6bf-b1a8-4a6f-8f89-4f6c1a2d9a94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['text'],\n",
            "    num_rows: 74004228\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "ds_full = load_dataset('bookcorpus',split='all')\n",
        "pprint(ds_full)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec896259-edc8-46ba-afac-9ea4602a096a",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "ec896259-edc8-46ba-afac-9ea4602a096a"
      },
      "source": [
        "The dataset contains 74 million sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f402be86-1a2d-4b15-8973-c8a1d9250e89",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "f402be86-1a2d-4b15-8973-c8a1d9250e89"
      },
      "source": [
        "The dataset contains about 1 billion words (**Exercise:** write code to get the exact number.)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cfd9608-d3c3-46e5-b35b-9357082f8478",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "4cfd9608-d3c3-46e5-b35b-9357082f8478"
      },
      "source": [
        "There are 71,598 samples that contain a single word."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76a71faf-f7e2-4852-bd30-76645996244d",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "76a71faf-f7e2-4852-bd30-76645996244d"
      },
      "source": [
        "The context length of the gpt-2 model is 1024"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "026ea49f-0a15-44d8-a6d1-15041b90d470",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "026ea49f-0a15-44d8-a6d1-15041b90d470"
      },
      "source": [
        "There are 50 samples that are larger than the context length of the model (with the largest sample containing 65,852 elements)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44f257c3-d6e6-4cae-b36b-1ba46d19b99f",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "44f257c3-d6e6-4cae-b36b-1ba46d19b99f"
      },
      "source": [
        "Let us randomly select one million samples from the 74 million to better understand the distribution, excluding the 50 largest samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec742be0-394c-4c21-b2fb-9787475fc33b",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "ec742be0-394c-4c21-b2fb-9787475fc33b"
      },
      "outputs": [],
      "source": [
        "#this cell will be hidden from the presentation\n",
        "with open('misc/bc_stats.json','r') as f:\n",
        "    bc_stats = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdd475b4-fcff-45ca-899e-5ebb6a0dfe3b",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "fdd475b4-fcff-45ca-899e-5ebb6a0dfe3b",
        "outputId": "dd9a0eb0-6925-4ce2-c89d-fea8ce7890a5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import random\n",
        "sorted_len = bc_stats['len_samples_sorted']\n",
        "bins = np.unique(sorted_len)\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.hist(random.sample(sorted_len[0:-50],k=10**6),bins=bins[0:150])\n",
        "plt.xlabel('Sequence length')\n",
        "plt.ylabel('count')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04161ecf-154f-44e6-bd42-9c2eac87c9a3",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "04161ecf-154f-44e6-bd42-9c2eac87c9a3"
      },
      "source": [
        "The length of a majority of the samples is far less than 60 and the average length is 13"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05a3b452-e187-4ac8-af02-95143a749435",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "05a3b452-e187-4ac8-af02-95143a749435"
      },
      "source": [
        "<h1 style=\"color:Tomato;\"> Tokenization </h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfeab982-334b-4ce0-9e05-2b000fed79b6",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "dfeab982-334b-4ce0-9e05-2b000fed79b6"
      },
      "source": [
        "The next step is to tokenize the samples using the `PreTrainedTokenizer`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c2b9ff5-e335-4aff-9920-02a1b10b7def",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "7c2b9ff5-e335-4aff-9920-02a1b10b7def"
      },
      "source": [
        "We can use the `hopper` tokenizer that we have trained in the previous experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "908bc1cf-dbc6-49e5-a373-c61f8e53bc37",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "908bc1cf-dbc6-49e5-a373-c61f8e53bc37",
        "outputId": "602dd681-e8ff-47cb-ba97-7c186475788b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PreTrainedTokenizerFast(name_or_path='../Week-2/hopper', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'pad_token': '[PAD]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
            "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t1: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "hopper_tokenizer = AutoTokenizer.from_pretrained('../Week-2/hopper')\n",
        "print(hopper_tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "891fedcf-cd43-4013-9860-a409913d53e9",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "891fedcf-cd43-4013-9860-a409913d53e9"
      },
      "source": [
        "Let us pass a batch of samples with padding enabled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b219020d-4c29-400f-b466-84e30ba70463",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "b219020d-4c29-400f-b466-84e30ba70463",
        "outputId": "6a9ed7ae-f429-4d83-8730-052eac6b912c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[2462, 19, 149, 277, 162, 6456, 422, 131, 1559, 536, 19, 2301, 201, 177, 9774,\n",
            "  21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "  0],\n",
            " [212, 297, 289, 456, 208, 46, 20830, 1420, 214, 4099, 1171, 139, 11126, 21, 0,\n",
            "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "  0],\n",
            " [178, 206, 337, 7656, 14, 64, 1147, 303, 174, 503, 214, 2363, 2310, 21, 0, 0,\n",
            "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "  0],\n",
            " [149, 14, 49, 946, 131, 3760, 880, 375, 3446, 19, 3766, 149, 166, 46, 545,\n",
            "  1185, 200, 131, 61, 93, 17794, 19, 212, 201, 2596, 9302, 19, 1050, 201, 163,\n",
            "  3186, 19, 5696, 166, 2270, 5194, 138, 717, 178, 278, 2596, 21]]\n"
          ]
        }
      ],
      "source": [
        "bs = 4 # batch_size\n",
        "model_inputs = hopper_tokenizer(ds_full[0:bs]['text'],padding=True)\n",
        "pprint(model_inputs['input_ids'],compact=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a7df779-dbbc-4dfe-9fa1-6e0b90a6b367",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "0a7df779-dbbc-4dfe-9fa1-6e0b90a6b367"
      },
      "source": [
        "What happens if a batch contains a sample of length 1 and 50?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39a4fbeb-afdd-49c5-8a96-01c1945e03ac",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "39a4fbeb-afdd-49c5-8a96-01c1945e03ac"
      },
      "source": [
        "We append 49 zeros to that shortest sample! It is a waste of compute (while pretraining)!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8b2eea5-4729-4118-a851-b17f536a9d13",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "d8b2eea5-4729-4118-a851-b17f536a9d13"
      },
      "source": [
        "Moreover, the samples in the dataset  maintain continuity with each other."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a3124fb-b692-4314-adae-faa57e2ba5fc",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "4a3124fb-b692-4314-adae-faa57e2ba5fc",
        "outputId": "0f10fc8b-befe-4136-8fea-b203dd20a928"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 'he loved sitting between her brothers on the couch and watching tv .',\n",
            " 1: 'while it was good that he had so many male role models , she only hoped '\n",
            "    \"he had n't inherited too much of his father 's personality .\",\n",
            " 2: 'after megan watched them disappear in the crowd of family and friends '\n",
            "    'waiting in the church alcove , she bypassed everyone by turning right and '\n",
            "    'heading down the hallway .',\n",
            " 3: 'at the last door on the right , she knocked .',\n",
            " 4: \"`` it 's me , megan . ''\",\n",
            " 5: \"emma 's best friend , casey , answered the door .\",\n",
            " 6: \"`` well , if it is n't the fairy godmother , '' she mused with a grin .\",\n",
            " 7: 'after megan stepped inside , casey threw her arms around her .',\n",
            " 8: \"megan had only met her a few times , but it was hard not liking emma 's \"\n",
            "    'vivacious and outgoing friend .',\n",
            " 9: \"casey 's long brown hair was pulled back in a lose knot , and she wore a \"\n",
            "    'demure black slip dress and heels .'}\n"
          ]
        }
      ],
      "source": [
        "pprint({id:example for id,example in enumerate(ds_full[ ]['text'])})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7397715-c4e3-4659-8506-c335241e899c",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "c7397715-c4e3-4659-8506-c335241e899c"
      },
      "source": [
        "Therefore, to use the available compute effectively, we can concatenate the samples so that the length of the concatenated sample equals the model's context length."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fc518d1-506b-44b1-80e7-ced101ea3adf",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "1fc518d1-506b-44b1-80e7-ced101ea3adf"
      },
      "source": [
        "It requires us to tokenize the samples and concatenate the tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fea76a4-4670-44c3-a129-3b61ef76be07",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "2fea76a4-4670-44c3-a129-3b61ef76be07"
      },
      "source": [
        "Therefore, we do not need to use the `padding` token for pretraining."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db7c2264-5c28-4344-bbf4-24024cd410d1",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "db7c2264-5c28-4344-bbf4-24024cd410d1"
      },
      "source": [
        "Let's use the `gpt2 tokenizer` (uses Bytelevel BPE). We can simply load it from the hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f45cc8b8-b759-4f1c-ad12-90385b72fcc4",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "f45cc8b8-b759-4f1c-ad12-90385b72fcc4",
        "outputId": "f392641a-408c-4dba-d32a-2002908aad3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
            "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
            "}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/dlp/.dlp/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
        "print(tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac46fe56-bdae-45ad-bfdb-2f793d156964",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "ac46fe56-bdae-45ad-bfdb-2f793d156964"
      },
      "source": [
        "Note the details such as `vocab_size`, `model_max_length` and `special_tokens` (all the special tokens expected by HF `PreTrainedTokenizerFast` are mapped to `<|endoftext|>` token that was originally used by the gpt2 tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "144bab7f-0d6d-4782-b00d-1dd73d01dff7",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "144bab7f-0d6d-4782-b00d-1dd73d01dff7"
      },
      "source": [
        "The parameter `padding_side` is set to `right`, but since no padding token is used, we should add a padding token to avoid errors from HF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f392464-d111-48c5-9dfa-ceb8bf1ef4eb",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "5f392464-d111-48c5-9dfa-ceb8bf1ef4eb"
      },
      "outputs": [],
      "source": [
        "tokenizer.pad_token = '<|endoftext|>'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69958ce7-015e-47fe-b256-17007a4f2df0",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "69958ce7-015e-47fe-b256-17007a4f2df0"
      },
      "source": [
        "Define a **mapping** function that takes a batch of samples and returns `input_ids` and `attention_mask` such that the length of `input_ids` is 1024 for all samples. (Take this as an exercise.)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a971bbed-2433-4547-bcaf-a845178be0fb",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "a971bbed-2433-4547-bcaf-a845178be0fb"
      },
      "source": [
        "We did this and stored it as a separate dataset. Now, let's load it from the disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e0283c4-75e8-4dfe-b0de-5e3af014a9d9",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "2e0283c4-75e8-4dfe-b0de-5e3af014a9d9"
      },
      "outputs": [],
      "source": [
        "ds_chunked = load_from_disk('data/BC_Chunked')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf3a04cc-0dcb-4cb5-9765-6d71a3dcfa65",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "cf3a04cc-0dcb-4cb5-9765-6d71a3dcfa65",
        "outputId": "e96decfe-130d-46f0-dd1d-be49f77e061e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['input_ids', 'attention_mask'],\n",
            "    num_rows: 1055117\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(ds_chunked)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2bc2562-7058-4253-a801-e18136d7e2a2",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "c2bc2562-7058-4253-a801-e18136d7e2a2"
      },
      "source": [
        "**Quick check:** <br>\n",
        "1. There are 1,055,117 samples.\n",
        "2. Each sample has a length of 1024\n",
        "3. Therefore, the total number of tokens is $1055117 \\times 1024 = 1.08$ billion tokens.\n",
        "4. This confirms that no extra tokens were added."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31273060-8799-4636-9506-06f1d366f3b7",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "31273060-8799-4636-9506-06f1d366f3b7"
      },
      "source": [
        "<h1 style=\"color:Tomato;\"> Data Loader </h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "172f73ed-f58a-4d25-be14-5330a3a69623",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "172f73ed-f58a-4d25-be14-5330a3a69623"
      },
      "source": [
        "Split the dataset into train and test splits (setting seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e835e8b-65aa-4049-83de-431f5982e221",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "3e835e8b-65aa-4049-83de-431f5982e221",
        "outputId": "c98463ac-d957-4eac-dea6-07d9b9cf33be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['input_ids', 'attention_mask'],\n",
            "        num_rows: 1047731\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['input_ids', 'attention_mask'],\n",
            "        num_rows: 7386\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "ds_split = ds_chunked.train_test_split(test_size=0.007,seed=42)\n",
        "print(ds_split)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbac30a4-f26e-4e49-a231-388d96b193bd",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "bbac30a4-f26e-4e49-a231-388d96b193bd"
      },
      "source": [
        "Recall that the `DataLoader` prepares the data for the model. The prepartion includes shuffling the data, **collating** a batch of samples with or without padding, and distributing it across multiple gpus or nodes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21b8bf4f-519c-46de-8e0f-1bad1bb75333",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "21b8bf4f-519c-46de-8e0f-1bad1bb75333"
      },
      "source": [
        "The collate function varies based on the model's training objective (e.g., CLM, MLM, PLM). Therefore, Hugging Face provides several commonly used collate functions: <br>\n",
        "1. DataCollatorForSeq2Seq\n",
        "2. DataCollatorForLanguageModelling\n",
        "3. DefaultDataCollator\n",
        "\n",
        "[Doc](https://huggingface.co/docs/transformers/main/main_classes/data_collator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b1a2d00-b9aa-44b4-b279-31274d6ffdce",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "7b1a2d00-b9aa-44b4-b279-31274d6ffdce"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForLanguageModeling(tokenizer,mlm=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01f0fc44-76eb-458d-a5d4-1612af77cc6b",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "01f0fc44-76eb-458d-a5d4-1612af77cc6b"
      },
      "source": [
        "HF uses this `data_collator` function internally. However, let’s take a closer look at what it does using the `DataLoader` from PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aba9dd40-7f43-459c-a622-348be5def3f9",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "aba9dd40-7f43-459c-a622-348be5def3f9"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82d1d29a-baf0-4cd1-ac76-12eb86a41980",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "82d1d29a-baf0-4cd1-ac76-12eb86a41980"
      },
      "outputs": [],
      "source": [
        "dataloader = DataLoader(dataset=ds_split['train'],\n",
        "                        collate_fn=data_collator,\n",
        "                        batch_size=4,\n",
        "                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b8405ac-bd11-4f42-b35b-ea33d151b27b",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "9b8405ac-bd11-4f42-b35b-ea33d151b27b",
        "outputId": "640746de-3d95-4fa0-8688-35a27305a786"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1]]),\n",
            " 'input_ids': tensor([[13769,   644,   262,  ...,  1323,   837,  8591],\n",
            "        [14262,   616, 17841,  ...,   423,   345, 21256],\n",
            "        [17007,   873,   262,  ...,   302,   276,   705],\n",
            "        [  503,   286,   262,  ...,   764,  7091,   550]]),\n",
            " 'labels': tensor([[13769,   644,   262,  ...,  1323,   837,  8591],\n",
            "        [14262,   616, 17841,  ...,   423,   345, 21256],\n",
            "        [17007,   873,   262,  ...,   302,   276,   705],\n",
            "        [  503,   286,   262,  ...,   764,  7091,   550]])}\n"
          ]
        }
      ],
      "source": [
        "for batch in dataloader:\n",
        "    pprint(batch)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9103779-f938-42fd-8fa3-911592551eb7",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "e9103779-f938-42fd-8fa3-911592551eb7"
      },
      "source": [
        "1. It returns (by default) the attributes as PyTorch `tensor` objects instead of Python `lists`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcb1fd77-f940-4343-b858-70a5b8b66212",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "bcb1fd77-f940-4343-b858-70a5b8b66212"
      },
      "source": [
        "2. It also returns the labels; for CLM, the `input_ids` serve as the labels with a shift (the shift happens in the training loop)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da84352f-e6f2-47f8-a8d2-2cf53f8c6886",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "da84352f-e6f2-47f8-a8d2-2cf53f8c6886"
      },
      "source": [
        "<h1 style=\"color:Tomato;\"> Initialize the Model </h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50d17dd6-b1b4-40e2-8c4f-2763e817172c",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "50d17dd6-b1b4-40e2-8c4f-2763e817172c"
      },
      "source": [
        "We can build the model in PyTorch and Wrap it using HF `PreTrainedConfig` class"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "898c1e5f-14e1-4c19-beac-09b7e62dc4bf",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "898c1e5f-14e1-4c19-beac-09b7e62dc4bf"
      },
      "source": [
        "HF already has the GPT architecture built in, with over 350,000 models available in the hub. We can load these models and **modify the configuration** to customize."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2c640bb-c689-4d58-b6bd-efbad288453b",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "a2c640bb-c689-4d58-b6bd-efbad288453b",
        "outputId": "c030ced1-7c77-41e1-c743-adb512938ad6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.44.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "configuration = GPT2Config()\n",
        "pprint(configuration)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f316a28c-d906-45df-ba09-4661b083bcaf",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "f316a28c-d906-45df-ba09-4661b083bcaf"
      },
      "source": [
        "Now, we can build the model with the Language Modelling head with the weights **initialized randomly**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b52143c4-4a6c-477e-bcf2-f26b1759a5be",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "b52143c4-4a6c-477e-bcf2-f26b1759a5be"
      },
      "outputs": [],
      "source": [
        "model = GPT2LMHeadModel(configuration)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7acc6202-6152-4c4f-ba22-e99d95ad9701",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "7acc6202-6152-4c4f-ba22-e99d95ad9701",
        "outputId": "3e6edb82-1b79-4376-91b6-4e6d46739b20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50257, 768)\n",
            "    (wpe): Embedding(1024, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-11): 12 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2SdpaAttention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf3c31e3-e782-488e-bcf6-20507faf44d9",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "cf3c31e3-e782-488e-bcf6-20507faf44d9"
      },
      "source": [
        "**Quick Check:** vocab size: 50257, embedding dim: 768, learnable position embedding (pe), uses Scaled Dot Product Attention (SDPA)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "969e19f6-063c-47c4-aefd-f40d8dadce45",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "969e19f6-063c-47c4-aefd-f40d8dadce45"
      },
      "source": [
        "Finally, let's count the number of Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0540169-cc4b-49f8-a2d2-2634c44c7f79",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "a0540169-cc4b-49f8-a2d2-2634c44c7f79",
        "outputId": "2613c00d-047a-4e3c-bda2-77b8e23aca0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Parameters:124.44M\n"
          ]
        }
      ],
      "source": [
        "num_parameters = 0\n",
        "for param in model.parameters():\n",
        "    num_parameters += param.numel()\n",
        "print(f'Number of Parameters:{num_parameters/10**6:.2f}M')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5597d0d2-f1eb-4e37-8e1a-9ea34cd42acc",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "5597d0d2-f1eb-4e37-8e1a-9ea34cd42acc"
      },
      "source": [
        "<h1 style=\"color:Tomato;\"> Train the Model </h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1aaec482-0201-4a69-b31a-3c67841177e0",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "1aaec482-0201-4a69-b31a-3c67841177e0"
      },
      "source": [
        "Training a model requires the following sequence of operations as shown in the figure below"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77fafdf1-b933-4364-aea1-132335390372",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "77fafdf1-b933-4364-aea1-132335390372"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/Arunprakash-A/Modern-NLP-with-Hugging-Face/refs/heads/main/Notebooks/images/training_loop.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32949427-e70f-42b8-8b18-69a61d78961d",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "32949427-e70f-42b8-8b18-69a61d78961d"
      },
      "source": [
        "1. Get a batch of samples.\n",
        "2. Make predictions.\n",
        "3. Compute loss.\n",
        "4. Compute gradients.\n",
        "5. Choose a learning rate scheduler.\n",
        "6. Choose an optimizer and set its hyperparameters.\n",
        "7. Update the weights.\n",
        "8. repeat until a criterion is met (convergence, compute credits, time,etc.,)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efb22161-85e5-4c05-b92d-3508d299c822",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "efb22161-85e5-4c05-b92d-3508d299c822"
      },
      "source": [
        "Apart from these steps, we may need to set parameters for [efficient training](https://huggingface.co/docs/transformers/v4.29.1/en/perf_train_gpu_one) strategies in both single and multi-GPU settings, as well as perform experiment tracking and logging."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c2466df-7dfb-45ab-b92a-dec7336c46c9",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "7c2466df-7dfb-45ab-b92a-dec7336c46c9"
      },
      "source": [
        "We use wandb for experiment tracking."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a522606-c002-4cb3-98fd-f7dcdb26b69f",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "6a522606-c002-4cb3-98fd-f7dcdb26b69f"
      },
      "source": [
        "```python\n",
        "wandb.init(\n",
        "    project=\"DLP-GPT2-Node-1\",     \n",
        "    config={\n",
        "        \"batch_size\":16,        \n",
        "        \"dataset\": \"Bookcorpus-74M\",\n",
        "    },\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d751ac83-23b2-413a-8cb0-98250c28b9a7",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "d751ac83-23b2-413a-8cb0-98250c28b9a7"
      },
      "source": [
        "All these training complexities are managed by two functions from the Transformers library: `TrainingArguments` and `Trainer`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fa81302-7b50-4664-b08e-e10cf8b82bde",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "3fa81302-7b50-4664-b08e-e10cf8b82bde"
      },
      "source": [
        "Let's look at a few important arguments"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4afe7f9-40ea-4c72-afed-09841cbddf58",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "d4afe7f9-40ea-4c72-afed-09841cbddf58"
      },
      "source": [
        "`eval_steps`: Compute validation loss every 500 steps.<br>\n",
        "`per_device_train_batch_size`: 8 samples (requires about 27 GB of memory). <br>\n",
        "`per_device_eval_batch_size` : 8 samples (can be larger since gradients are not computed).<br>\n",
        "`tf32`: whether or not to use the tf32 datatype (for matrix multiplication) to increase computation speed.<br>\n",
        "`bf16`: whether or not to use the bf16 (high dynamic range) for mixed precision training.<br>\n",
        "`fp16`: whether or not to use the fp16 (low dynamic range) for mixed precision training. <br>\n",
        "`num_train_epochs`: 1 (budget is the bottleneck)<br>\n",
        "`save_steps`: Store model checkpoints every 1000 steps (after processing 8 million tokens).<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "704291aa-fb8e-4f44-82e0-8a6aac04b8ea",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "704291aa-fb8e-4f44-82e0-8a6aac04b8ea"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments( output_dir='out',\n",
        "                                  eval_strategy=\"steps\",\n",
        "                                  eval_steps=500,\n",
        "                                  num_train_epochs=1,\n",
        "                                  per_device_train_batch_size=8,\n",
        "                                  per_device_eval_batch_size=8,\n",
        "                                  bf16=False,\n",
        "                                  fp16=False,\n",
        "                                  tf32=False,\n",
        "                                  adam_beta1=0.9,\n",
        "                                  adam_beta2=0.999,\n",
        "                                  learning_rate=2e-5,\n",
        "                                  weight_decay=0.01,\n",
        "                                  gradient_accumulation_steps=1,\n",
        "                                  logging_strategy=\"steps\",\n",
        "                                  logging_steps = 500,\n",
        "                                  save_steps=1000,\n",
        "                                  save_total_limit=15,\n",
        "                                  report_to='wandb',\n",
        "                                 )\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5642c0af-3909-45ad-bf66-366459151dfd",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "5642c0af-3909-45ad-bf66-366459151dfd"
      },
      "source": [
        "Finally, let's use the `Trainer` API to set up the entire training pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a2315f2-e173-46bf-92a1-f0c931e0007d",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "8a2315f2-e173-46bf-92a1-f0c931e0007d"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(model=model,\n",
        "                 args = training_args,\n",
        "                 train_dataset=ds_split[\"train\"],\n",
        "                 eval_dataset= ds_split[\"test\"],\n",
        "                 data_collator = data_collator)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5833996e-3d5a-458e-9466-d08e7adad214",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "5833996e-3d5a-458e-9466-d08e7adad214"
      },
      "source": [
        "Just call `.train()` method, sit back, and watch for OOM error :-)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c206648-42b6-48e3-9a81-3d88ad6c74fb",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "8c206648-42b6-48e3-9a81-3d88ad6c74fb"
      },
      "source": [
        "```python\n",
        "results = trainer.train()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00d31c8f-ff58-4593-a97f-1faabaf28757",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "00d31c8f-ff58-4593-a97f-1faabaf28757"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/Arunprakash-A/Modern-NLP-with-Hugging-Face/refs/heads/main/Notebooks/images/sample_out.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec64543a-a447-45a6-a7a5-ae1a59089d12",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "ec64543a-a447-45a6-a7a5-ae1a59089d12"
      },
      "source": [
        "We ran the model on three different GPUs: <br>\n",
        "1. V100 with **32 GB** (no support for: tf32, bf16)\n",
        "2. 2xL4 **48 GB** (supports bf16,tf32)\n",
        "3. A node with A100 **80 GB** (supports bf16, tf32)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0826c8bc-74f3-4493-9531-add5c17f1c6d",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "0826c8bc-74f3-4493-9531-add5c17f1c6d"
      },
      "source": [
        "<h1 style=\"color:Tomato;\"> Efficient Training </h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54dd8b1b-ba41-404e-a0e4-5fb708d84eea",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "54dd8b1b-ba41-404e-a0e4-5fb708d84eea"
      },
      "source": [
        "We know that increasing the batch size helps achieve faster convergence. However, for a given GPU, how can we increase the batch size without raising an OOM error?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c54d0830-1d7e-4a2a-8a9a-bc56a2a84d8d",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "c54d0830-1d7e-4a2a-8a9a-bc56a2a84d8d"
      },
      "source": [
        "How can we increase computation speed?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3935ca4-b977-47b0-b2c9-9168f848e60f",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "f3935ca4-b977-47b0-b2c9-9168f848e60f"
      },
      "source": [
        "Setting following arguments help us achieve these objectives <br>\n",
        "`tf32`: whether or not to use the tf32 datatype (for matrix multiplication) to increase computation speed.<br>\n",
        "`bf16`: whether or not to use bf16 (high dynamic range) for mixed precision training.<br>\n",
        "`fp16`: whether or not to use fp16 (low dynamic range) for mixed precision training. <br>\n",
        "`gradient_accumulation_steps`: Use gradient accumulation for increased batch size"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "750370e4-3dc1-41b6-8ab5-d36f3fbd1ba9",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "750370e4-3dc1-41b6-8ab5-d36f3fbd1ba9"
      },
      "source": [
        "We will not go into the details; you may refer to this [page]((https://huggingface.co/docs/transformers/v4.29.1/en/perf_train_gpu_one)) on HF."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42190397-8a5c-4c12-a1a4-19fd57b5797a",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "42190397-8a5c-4c12-a1a4-19fd57b5797a"
      },
      "source": [
        "However, we have used a combination of these arguments to demonstrate how they are helpful."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bf58fb1-49ef-4b44-9861-a3023e922258",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "0bf58fb1-49ef-4b44-9861-a3023e922258"
      },
      "source": [
        "<h1 style=\"color:Tomato;\"> Experiment Tracking with WandB </h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06f96694-c969-4df2-881a-ebe31659b327",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "06f96694-c969-4df2-881a-ebe31659b327",
        "outputId": "a35df5ba-850a-4f51-cbd7-9d2a31890ac4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"600\"\n",
              "            src=\"https://wandb.ai/a-arun283-iit-madras/DLP-GPT2-Node-1/reports/DLP-PreTraining-GPT-2--Vmlldzo5NTgxMTUx\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7efb79a66230>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import IFrame\n",
        "IFrame(\"https://wandb.ai/a-arun283-iit-madras/DLP-GPT2-Node-1/reports/DLP-PreTraining-GPT-2--Vmlldzo5NTgxMTUx\", width=\"100%\", height=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b080e6b2-97d8-4d08-82af-cce9f1d62ccf",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "b080e6b2-97d8-4d08-82af-cce9f1d62ccf"
      },
      "source": [
        "<h1 style=\"color:Tomato;\"> Text Generation </h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f80e1580-6246-4cf5-85c4-5128de1fc54a",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "f80e1580-6246-4cf5-85c4-5128de1fc54a"
      },
      "source": [
        "We can load the model with the pretrained weights, which now come from different checkpoints stored in the `out/checkpoint-xxxx/` directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe8d4391-89fd-49a5-8bf9-85f05f9830cf",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "fe8d4391-89fd-49a5-8bf9-85f05f9830cf"
      },
      "outputs": [],
      "source": [
        "#after seeing 128(bs)*1024(n_ctxt)*1000(steps)=131 million tokens\n",
        "model =GPT2LMHeadModel.from_pretrained('out/checkpoint-1000/')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "477b37f2-150e-4041-8c04-c6b37f1a3cee",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "477b37f2-150e-4041-8c04-c6b37f1a3cee"
      },
      "source": [
        "**Note:** We must ensure that the input to the model is a PyTorch tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0bb789f-3c51-4fa0-b209-9e61ea30998e",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "e0bb789f-3c51-4fa0-b209-9e61ea30998e",
        "outputId": "f338857d-136e-4404-9c9f-f6ac6fb12b39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[1616,  514,  423,  257, 1257, 1909,   13, 1867,  466,  345,  910,   30]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ],
      "source": [
        "prompt = \"let us have a fun today. What do you say?\"\n",
        "inputs = tokenizer(prompt,return_tensors='pt',padding=True) # return torch tensor\n",
        "print(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bb0472e-424d-45f5-ab54-68f8cfae376c",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "8bb0472e-424d-45f5-ab54-68f8cfae376c"
      },
      "source": [
        "* Generate `100` tokens\n",
        "* Use `top-p` decoding strategy. Refer to Week 3 of [Introduction to Large Language Models](http://www.cse.iitm.ac.in/~miteshk/llm-course.html) for more information on various decoding strategies.\n",
        "* You may visit the [documentation](https://huggingface.co/docs/transformers/v4.45.1/en/generation_strategies#text-generation-strategies) to explore all available decoding strategies in HF"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15c0e1c4-6e75-4b63-9887-f501539fa296",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "15c0e1c4-6e75-4b63-9887-f501539fa296"
      },
      "source": [
        "We can call `.generate()` method of the model and pass the inputs (**inputs unpack all the keys (`input_ids`,`attention_mask`,..))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e325493-748f-4a16-add3-dd9ed47c04ff",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "9e325493-748f-4a16-add3-dd9ed47c04ff",
        "outputId": "4c066d15-ce45-44e0-fd12-3ecb397467bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1616,   514,   423,   257,  1257,  1909,    13,  1867,   466,   345,\n",
            "           910,    30, 10148,    72,   531,   837,  7559,   475,   345,   765,\n",
            "           284,   307,   257,  1310,   517,   546,   340,   764,    72,   466,\n",
            "           299,   470,   761,   284,   651,   284,   766,   340,   764, 10148,\n",
            "           258,   705,    76,   407,   257,  1256,   286,   262,   835,   764,\n",
            "           258,   373,   257,  1310,   517,   764, 15506,   340,   373,   257,\n",
            "          1256,   764, 10148, 15506,   326,   345,   466,   299,   470,   307,\n",
            "           257,  1310,   764, 10148, 15506,   345,   547,   299,   470,   765,\n",
            "           284,   262,   938,  1755,   764, 10148, 15506,  1312,   705,   297,\n",
            "           307,   257,  1256,   286,   616,  1204,   764, 10148,    72,   531,\n",
            "           837,   290,   788,   339,   750,   299,   470,   765,   284,   262,\n",
            "          2156,   764]])\n"
          ]
        }
      ],
      "source": [
        "outputs = model.generate(**inputs, max_new_tokens=100, do_sample=True, top_k=10, top_p=0.95)\n",
        "print(outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7507644-3575-49d0-abc0-a39a91f4445e",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "e7507644-3575-49d0-abc0-a39a91f4445e"
      },
      "source": [
        "First, we need to convert the predicted token_ids back to tokens, and then to words using the tokenizer's decoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62014bf2-f6af-4556-9c7f-dea329b1bf90",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "62014bf2-f6af-4556-9c7f-dea329b1bf90",
        "outputId": "c850077c-ce13-4471-e000-5d4b06c3b883"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"let us have a fun today. What do you say? ''i said, `` but you want to be a little more about it.i don't need to get to see it. ''he'm not a lot of the way.he was a little more.`` it was a lot. ''`` that you don't be a little. ''`` you weren't want to the last night. ''`` i 'll be a lot of my life. ''i said, and then he didn't want to the house.\"]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab31fe4a-f4f2-4703-bea7-799b7938356f",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "ab31fe4a-f4f2-4703-bea7-799b7938356f"
      },
      "source": [
        "**Checkpoint-4000:** (after seeing 520 million tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d486618d-2e12-4a14-bd48-a1739a6cdcb3",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "d486618d-2e12-4a14-bd48-a1739a6cdcb3",
        "outputId": "aa601938-550a-42ed-cd74-52d7bd27a5f6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[\"let us have a fun today. What do you say? ''`` what's going on? ''i'm a little bit, but it's all i'm sure i'm not going to know.`` what's going on? ''i ask, trying to get up with it.`` don't think of anything, '' i say, looking at him.`` i'm not going to be a big deal. ''he's still trying to make me feel the way out of my mouth.`` and i '\"]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model =GPT2LMHeadModel.from_pretrained('out/checkpoint-4000/')\n",
        "prompt = \"let us have a fun today. What do you say?\"\n",
        "inputs = tokenizer(prompt,return_tensors='pt',padding=True)\n",
        "outputs = model.generate(**inputs, max_new_tokens=100, do_sample=True, top_k=10, top_p=0.95)\n",
        "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8ace163-024d-4fed-88b8-f784681ad8b6",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "e8ace163-024d-4fed-88b8-f784681ad8b6"
      },
      "source": [
        "**Checkpoint-8000:** (after seeing 1 billion tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a959370f-58d7-4cde-9827-fccb3eb4495a",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "a959370f-58d7-4cde-9827-fccb3eb4495a",
        "outputId": "8393f232-516e-41f2-f50e-c56323ccfd35"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[\"let us have a fun today. What do you say? ''`` i know, '' i answered.`` i don't know how to start with you. ''`` i'm not going to have to tell you the truth. ''i nodded, trying to make a face of a smile.i didn't care if she was being an ass**le.i knew how long i 'd been in my life when i 'd been a man, and i had to make the right thing up to her.`` what? ''`` what\"]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model =GPT2LMHeadModel.from_pretrained('out/checkpoint-8185/')\n",
        "prompt = \"let us have a fun today. What do you say?\"\n",
        "inputs = tokenizer(prompt,return_tensors='pt',padding=True)\n",
        "outputs = model.generate(**inputs, max_new_tokens=100, do_sample=True, top_k=10, top_p=0.95)\n",
        "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a37f5ed1-e37c-44b9-adfe-d7e3efb936bc",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "a37f5ed1-e37c-44b9-adfe-d7e3efb936bc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}